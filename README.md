# â³ Recursive Time & Stability-First AI

[![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC_BY--NC_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc/4.0/)

A collection of experiments exploring memory, catastrophic forgetting, and temporal modularity in neural networks.

**Author**: Vitali Sialedchyk

---

## ğŸ§  Core Thesis

Modern AI systems exist in "instantaneous time" â€” optimizing only for the current data batch. This project implements the **Stability-First** hypothesis:

> **Time in an AI system is defined by structural inertia.** By treating weight stability as "System Time", we can prevent catastrophic forgetting and achieve modular, reversible learning.

---

## ğŸ“‚ Project Roadmap

| # | Project | Focus | Key Insight | Status |
|---|---------|-------|-------------|--------|
| **01** | Active Sleep (MNIST) | Generative Replay | Memory can be restored using VAE "dreams" without storing real data. | âœ… Complete |
| **02** | Temporal LoRA (GPT-2) | LLM Scaling | **Main success**: The "Time Mixer" router dynamically switches between knowledge epochs (Shakespeare vs Python) with **100% accuracy**. | ğŸŒŸ **Hero** |
| **03** | Stability-First Basic | Foundation | Preventing forgetting by protecting the backbone while maintaining interface plasticity. | âœ… Complete |
| **04** | Reversibility | Lazarus Effect | Memory is often latent, not erased. We recovered "forgotten" tasks from 0% to **94.65%** accuracy. | âœ… Complete |
| **05** | Full Suite | Benchmarking | Comparative analysis of 5 strategies (Fractal Time, Adaptive Pain, Dream Replay). | âœ… Complete |
| **06** | Subjective Time | Metacognition | **Novel**: A system with a "Critic" that automatically regulates its plasticity based on "surprise" (Surprise). | âœ… Complete |

---

## ğŸš€ Quick Start ("Hero" Experiment)

If you want to run just one experiment, choose **Temporal LoRA**. It demonstrates dynamic context switching in GPT-2.

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Run GPT-2 experiment
cd 02-temporal-lora-gpt2
python temporal_lora.py
```

Watch as the model automatically learns to route "To code or not to code" to the Shakespeare adapter, and "import torch" to the Python adapter.

---

## ğŸ“Š Key Results

### 1. Lazarus Effect (Latent Reversibility)

We proved that even when model accuracy on Task A drops to **0.00%** after training on Task B, knowledge remains encoded in the backbone.

**Recovery**: **94.65%** accuracy recovered with just 50 examples.

### 2. Time Mixer Accuracy (GPT-2)

In our Temporal LoRA experiment, the gating network successfully learned to distinguish semantic epochs.

**Router accuracy**: **100.0%** after contrastive calibration.

### 3. Subjective Time (The Critic)

In experiment #6, we showed how a system can autonomously regulate its learning rate (Î») based on prediction error (Surprise). This mimics dopamine function in the brain.

**Result**: Lambda dynamically adapts from 1805 (high Surprise) to 2647 (low Surprise).

---

## ğŸ“ Project Structure

```
D:\new\
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Common dependencies
â”‚
â”œâ”€â”€ 01-active-sleep-mnist/             # Project 1: Active Sleep (MNIST)
â”‚   â”œâ”€â”€ active_sleep.py
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ 02-temporal-lora-gpt2/            # Project 2: Temporal LoRA (GPT-2) ğŸŒŸ
â”‚   â”œâ”€â”€ temporal_lora.py
â”‚   â”œâ”€â”€ TEMPORAL_LORA_README.md
â”‚   â”œâ”€â”€ ACTIVE_SLEEP_FOR_MIXER.md
â”‚   â”œâ”€â”€ temporal_lora_mixer_weights.png
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ 03-stability-first-basic/          # Project 3: Stability-First (Basic)
â”‚   â”œâ”€â”€ run_demo.py
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ 04-stability-first-reversibility/  # Project 4: Stability-First (Reversibility)
â”‚   â”œâ”€â”€ run_demo.py
â”‚   â”œâ”€â”€ run_double_reversibility.py
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ 05-recursive-time-full-suite/      # Project 5: Full Experiment Suite
â”‚   â”œâ”€â”€ run_split_suite.py
â”‚   â”œâ”€â”€ run_double_reversibility.py
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ 06-subjective-time-critic/         # Project 6: Subjective Time (The Critic)
â”‚   â”œâ”€â”€ demo_6_subjective_time.py
â”‚   â”œâ”€â”€ subjective_time.png
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ docs/                               # Documentation
â”‚   â”œâ”€â”€ README.md                      # Full documentation
â”‚   â”œâ”€â”€ QUICK_START.md                  # Quick start
â”‚   â””â”€â”€ INDEX.md                        # Navigation
â”‚
â””â”€â”€ logs/                               # Experiment logs
    â”œâ”€â”€ 01-active-sleep-mnist.log
    â”œâ”€â”€ 02-temporal-lora-gpt2.log
    â”œâ”€â”€ 03-stability-first-basic.log
    â”œâ”€â”€ 04-stability-first-reversibility.log
    â”œâ”€â”€ 05-recursive-time-full-suite.log
    â”œâ”€â”€ 06-subjective-time-critic.log
    â””â”€â”€ RESULTS_SUMMARY.md             # Final report
```

---

## ğŸš€ Running All Experiments

### Project 1: Active Sleep (MNIST)
```bash
cd 01-active-sleep-mnist
pip install -r requirements.txt
python active_sleep.py
```
**Result**: Task A retention: **96.30%** âœ…

### Project 2: Temporal LoRA (GPT-2) ğŸŒŸ **HERO**
```bash
cd 02-temporal-lora-gpt2
pip install -r requirements.txt
python temporal_lora.py
```
**Result**: Router Accuracy: **100.0%** âœ…

### Project 3: Stability-First (Basic)
```bash
cd 03-stability-first-basic
pip install -r requirements.txt
python run_demo.py
```
**Result**: Task A retention: **93.52%** âœ…

### Project 4: Stability-First (Reversibility)
```bash
cd 04-stability-first-reversibility
pip install -r requirements.txt
python run_demo.py
python run_double_reversibility.py
```
**Result**: Task A retention: **94.65%** âœ…

### Project 5: Recursive-Time (Full Suite)
```bash
cd 05-recursive-time-full-suite
pip install -r requirements.txt
python run_split_suite.py
```
**Result**: All methods show **94-95%** retention âœ…

### Project 6: Subjective Time (The Critic)
```bash
cd 06-subjective-time-critic
pip install -r requirements.txt
python demo_6_subjective_time.py
```
**Result**: Lambda adapts dynamically (1805 â†’ 2647) âœ…

---

## ğŸ“ˆ Results Comparison Table

| Project | Method | Retention/Accuracy | Status |
|---------|--------|-------------------|--------|
| 01-active-sleep-mnist | Generative Replay | **96.30%** | âœ… |
| 02-temporal-lora-gpt2 | Time Mixer | Router: **100%** | âœ… **Success** |
| 03-stability-first-basic | Stability-First | **93.52%** | âœ… |
| 04-stability-first-reversibility | Stability-First | **94.65%** | âœ… |
| 05-recursive-time-full-suite | Multiple Methods | **94-95%** | âœ… |
| 06-subjective-time-critic | Adaptive Lambda | Lambda: 1805â†’2647 | âœ… |

---

## ğŸ¯ Key Takeaways

1. âœ… **Fractal nature of forgetting**: Forgetting occurs at all levels (adapters, routers)
2. âœ… **Stability-First is effective**: 93-95% retention vs 0% baseline
3. âœ… **Time Mixer works**: 100% accuracy after calibration
4. âœ… **Backbone features are critical**: Using hidden_states from GPT-2 solves the problem
5. âœ… **Subjective time works**: Lambda dynamically adapts based on Surprise

---

## ğŸ”§ Technical Details

### Windows Fixes
- âœ… `num_workers=0`, `pin_memory=False` in DataLoader
- âœ… Unicode symbols (Î”, Î») replaced with ASCII
- âœ… All scripts have `if __name__ == "__main__"`

### Dependencies
- torch
- torchvision
- numpy
- transformers (for project 2)
- matplotlib

---

## ğŸ“š Documentation

- **[docs/README.md](docs/README.md)** - Full documentation of all projects
- **[docs/QUICK_START.md](docs/QUICK_START.md)** - Quick start and overview
- **[docs/INDEX.md](docs/INDEX.md)** - Project navigation
- **[logs/RESULTS_SUMMARY.md](logs/RESULTS_SUMMARY.md)** - Final report of all experiments

---

## ğŸ¤ Citation

If you find this research useful, please use the following citation:

```bibtex
@misc{stability_first_ai,
  author = {Vitali Sialedchyk},
  title = {Stability-First AI: Memory and Recursive Stability as System Time},
  year = {2026},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/vitali-sialedchyk/stability-first-ai}}
}
```

---

## âš–ï¸ License & Commercial Use

This project is licensed under the **Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)**.

* âœ… **Free for:** Academic research, education, personal testing, and non-profit use.
* âŒ **Not allowed:** Commercial products, paid services, or corporate R&D without a separate agreement.

**Want to use Stability-First AI in your product?**
We offer commercial licensing options including support and architectural consulting.
ğŸ“© **Contact:** vitali@agdgroup.pl or via GitHub Issues.

See the [LICENSE](LICENSE) file for full terms and conditions.

---

## ğŸ† Achievements

1. âœ… Solved Time Mixer inversion problem (Router: 100% accuracy)
2. âœ… Proved Stability-First effectiveness (92-95% retention vs 0% baseline)
3. âœ… Demonstrated fractal nature of forgetting
4. âœ… Scaled to LLM (GPT-2) with LoRA adapters
5. âœ… Implemented subjective time with metacognitive regulator

---

**Last updated**: 2024  
**Status**: âœ… All 6 projects ready for publication
